{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os; os.environ[\"KERAS_BACKEND\"] = \"tensorflow\";\n",
    "from keras import backend as K\n",
    "\n",
    "# hack to make the image ordering from theano still usable\n",
    "# https://stackoverflow.com/questions/41651628/negative-dimension-size-caused-by-subtracting-3-from-1-for-conv2d\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "import utils2; reload(utils2)\n",
    "from utils2 import *\n",
    "\n",
    "import tensorflow as tf\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "\n",
    "K.set_session(sess)\n",
    "\n",
    "# set some config - might be able to just remove later\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gpu_options {\n",
       "  allow_growth: true\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'/device:GPU:0']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# util funtion to get avaiable GPUs from tensorflow point of view\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this placeholder will contain our input digits, as flat vectors\n",
    "img = tf.placeholder(tf.float32, shape=(None, 784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "\n",
    "# Keras layers can be called on TensorFlow tensors:\n",
    "x = Dense(128, activation='relu')(img)  # fully-connected layer with 128 units and ReLU activation\n",
    "x = Dense(128, activation='relu')(x)\n",
    "preds = Dense(10, activation='softmax')(x)  # output layer with 10 units and a softmax activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = tf.placeholder(tf.float32, shape=(None, 10))\n",
    "\n",
    "from keras.objectives import categorical_crossentropy\n",
    "loss = tf.reduce_mean(categorical_crossentropy(labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist_data = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "\n",
    "sess.run(tf.global_variables_initializer())  # - required for Tensorflow variable initialization\n",
    "\n",
    "with sess.as_default():\n",
    "    for i in range(100):\n",
    "        batch = mnist_data.train.next_batch(50)\n",
    "        train_step.run(feed_dict={img: batch[0],\n",
    "                                  labels: batch[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist_data = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SETUP \n",
    "batch_size = 256 # MNIST data is small, so my computer can surely handle this\n",
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST contains grayscale images, so we need to expand a dim\n",
    "# so that we got data in shape: (n_samples, n_channels, h, w)\n",
    "X_test = np.expand_dims(X_test, 1) # second dimension\n",
    "X_train = np.expand_dims(X_train, 1) # second dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 1, 28, 28), (10000, 1, 28, 28), dtype('uint8'))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, X_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1, 9], dtype=uint8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = onehot(y_train)\n",
    "y_test = onehot(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# normalize the input\n",
    "print(X_train.shape)\n",
    "mean_px = X_train.mean().astype(np.float32)\n",
    "std_px = X_train.std().astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000, 234, 39)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def norm_input(x): return (x - mean_px)/std_px\n",
    "# make keras' numpyArrayIterator\n",
    "gen = image.ImageDataGenerator()\n",
    "batches = gen.flow(X_train, y_train, batch_size=batch_size)\n",
    "test_batches = gen.flow(X_test, y_test, batch_size=batch_size)\n",
    "\n",
    "# new keras params:\n",
    "# steps_per_epoch: Total number of steps (batches of samples) \n",
    "# before declaring one epoch finished and starting the next\n",
    "# epoch.  similar for validation_steps\n",
    "steps_per_epoch = int(np.ceil(batches.n/batch_size))\n",
    "validation_steps = int(np.ceil(test_batches.n/batch_size))\n",
    "\n",
    "(batches.n, test_batches.n, steps_per_epoch, validation_steps) # show dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCHNORM + DROPOUT + DATA AUGMENTATION\n",
    "# Combine all the good stuff so far\n",
    "def get_model_bn_do():\n",
    "    \"\"\"WIll work if we set dim ordering correctly\"\"\"\n",
    "    model = Sequential([\n",
    "        Lambda(norm_input, input_shape=(1, 28, 28)),\n",
    "        Conv2D(32, (3, 3), activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Conv2D(32, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        BatchNormalization(axis=1),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        BatchNormalization(),\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "    model.compile(Adam(), loss='categorical_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bn_do = get_model_bn_do()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "234/234 [==============================] - 9s 37ms/step - loss: 0.1418 - acc: 0.9580 - val_loss: 0.0330 - val_acc: 0.9892\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3024ffe490>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# should ALWAYS use the default learning rates for a couple of epoch\n",
    "model_bn_do.fit_generator(batches, epochs=1,\n",
    "                steps_per_epoch=steps_per_epoch,\n",
    "                validation_steps=validation_steps, \n",
    "                validation_data=test_batches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0374 - acc: 0.9881 - val_loss: 0.0302 - val_acc: 0.9896\n",
      "Epoch 2/4\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0272 - acc: 0.9910 - val_loss: 0.0250 - val_acc: 0.9916\n",
      "Epoch 3/4\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0202 - acc: 0.9936 - val_loss: 0.0232 - val_acc: 0.9921\n",
      "Epoch 4/4\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0151 - acc: 0.9953 - val_loss: 0.0229 - val_acc: 0.9929\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3024345cd0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bn_do.optimizer.lr = 0.1 # shift-M to merge in command mode\n",
    "model_bn_do.fit_generator(batches, epochs=4,\n",
    "                steps_per_epoch=steps_per_epoch,\n",
    "                validation_steps=validation_steps, \n",
    "                validation_data=test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0134 - acc: 0.9959 - val_loss: 0.0272 - val_acc: 0.9911\n",
      "Epoch 2/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0102 - acc: 0.9964 - val_loss: 0.0279 - val_acc: 0.9918\n",
      "Epoch 3/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0103 - acc: 0.9967 - val_loss: 0.0283 - val_acc: 0.9915\n",
      "Epoch 4/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0123 - acc: 0.9958 - val_loss: 0.0286 - val_acc: 0.9925\n",
      "Epoch 5/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0086 - acc: 0.9975 - val_loss: 0.0240 - val_acc: 0.9930\n",
      "Epoch 6/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0063 - acc: 0.9979 - val_loss: 0.0306 - val_acc: 0.9906\n",
      "Epoch 7/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0076 - acc: 0.9975 - val_loss: 0.0306 - val_acc: 0.9918\n",
      "Epoch 8/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0077 - acc: 0.9974 - val_loss: 0.0255 - val_acc: 0.9925\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f30241bc110>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bn_do.optimizer.lr = 0.01 # shift-M to merge in command mode\n",
    "model_bn_do.fit_generator(batches, epochs=8,\n",
    "                steps_per_epoch=steps_per_epoch,\n",
    "                validation_steps=validation_steps, \n",
    "                validation_data=test_batches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0049 - acc: 0.9984 - val_loss: 0.0294 - val_acc: 0.9913\n",
      "Epoch 2/12\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0061 - acc: 0.9981 - val_loss: 0.0255 - val_acc: 0.9923\n",
      "Epoch 3/12\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0069 - acc: 0.9979 - val_loss: 0.0296 - val_acc: 0.9920\n",
      "Epoch 4/12\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0067 - acc: 0.9978 - val_loss: 0.0265 - val_acc: 0.9918\n",
      "Epoch 5/12\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0072 - acc: 0.9978 - val_loss: 0.0291 - val_acc: 0.9918\n",
      "Epoch 6/12\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0063 - acc: 0.9982 - val_loss: 0.0279 - val_acc: 0.9940\n",
      "Epoch 7/12\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0057 - acc: 0.9980 - val_loss: 0.0304 - val_acc: 0.9927\n",
      "Epoch 8/12\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0044 - acc: 0.9986 - val_loss: 0.0284 - val_acc: 0.9928\n",
      "Epoch 9/12\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0061 - acc: 0.9981 - val_loss: 0.0308 - val_acc: 0.9931\n",
      "Epoch 10/12\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0076 - acc: 0.9976 - val_loss: 0.0311 - val_acc: 0.9931\n",
      "Epoch 11/12\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0047 - acc: 0.9985 - val_loss: 0.0289 - val_acc: 0.9926\n",
      "Epoch 12/12\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0051 - acc: 0.9981 - val_loss: 0.0338 - val_acc: 0.9911\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3024347310>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bn_do.optimizer.lr = 0.001 # shift-M to merge in command mode\n",
    "model_bn_do.fit_generator(batches, epochs=12,\n",
    "                steps_per_epoch=steps_per_epoch,\n",
    "                validation_steps=validation_steps, \n",
    "                validation_data=test_batches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENSEMBLE ACCROSS ALL THESE MODELS\n",
    "# TODO: MAKE 6 MODELS LIKE THIS and average them\n",
    "def fit_model():\n",
    "    model_bn_do = get_model_bn_do()\n",
    "    model_bn_do.fit_generator(batches, epochs=8,\n",
    "                steps_per_epoch=steps_per_epoch,\n",
    "                validation_steps=validation_steps, \n",
    "                validation_data=test_batches)\n",
    "    \n",
    "    model_bn_do.optimizer.lr = 0.1 \n",
    "    model_bn_do.fit_generator(batches, epochs=4,\n",
    "                steps_per_epoch=steps_per_epoch,\n",
    "                validation_steps=validation_steps, \n",
    "                validation_data=test_batches)\n",
    "    \n",
    "    model_bn_do.optimizer.lr = 0.01 \n",
    "    model_bn_do.fit_generator(batches, epochs=8,\n",
    "                steps_per_epoch=steps_per_epoch,\n",
    "                validation_steps=validation_steps, \n",
    "                validation_data=test_batches)\n",
    "    \n",
    "    model_bn_do.optimizer.lr = 0.001 \n",
    "    model_bn_do.fit_generator(batches, epochs=8,\n",
    "                steps_per_epoch=steps_per_epoch,\n",
    "                validation_steps=validation_steps, \n",
    "                validation_data=test_batches)\n",
    "    return model_bn_do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "234/234 [==============================] - 8s 36ms/step - loss: 0.1453 - acc: 0.9583 - val_loss: 0.0420 - val_acc: 0.9863\n",
      "Epoch 2/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0394 - acc: 0.9876 - val_loss: 0.0469 - val_acc: 0.9850\n",
      "Epoch 3/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0268 - acc: 0.9918 - val_loss: 0.0250 - val_acc: 0.9922\n",
      "Epoch 4/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0189 - acc: 0.9936 - val_loss: 0.0260 - val_acc: 0.9917\n",
      "Epoch 5/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0160 - acc: 0.9947 - val_loss: 0.0250 - val_acc: 0.9911\n",
      "Epoch 6/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0148 - acc: 0.9949 - val_loss: 0.0283 - val_acc: 0.9913\n",
      "Epoch 7/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0125 - acc: 0.9958 - val_loss: 0.0268 - val_acc: 0.9924\n",
      "Epoch 8/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0105 - acc: 0.9965 - val_loss: 0.0267 - val_acc: 0.9924\n",
      "Epoch 1/4\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0081 - acc: 0.9973 - val_loss: 0.0270 - val_acc: 0.9928\n",
      "Epoch 2/4\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0080 - acc: 0.9972 - val_loss: 0.0298 - val_acc: 0.9917\n",
      "Epoch 3/4\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0105 - acc: 0.9965 - val_loss: 0.0300 - val_acc: 0.9925\n",
      "Epoch 4/4\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0075 - acc: 0.9973 - val_loss: 0.0253 - val_acc: 0.9924\n",
      "Epoch 1/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0066 - acc: 0.9977 - val_loss: 0.0248 - val_acc: 0.9928\n",
      "Epoch 2/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0069 - acc: 0.9979 - val_loss: 0.0249 - val_acc: 0.9930\n",
      "Epoch 3/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0063 - acc: 0.9980 - val_loss: 0.0273 - val_acc: 0.9928\n",
      "Epoch 4/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0066 - acc: 0.9977 - val_loss: 0.0243 - val_acc: 0.9938\n",
      "Epoch 5/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0054 - acc: 0.9980 - val_loss: 0.0275 - val_acc: 0.9923\n",
      "Epoch 6/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0079 - acc: 0.9972 - val_loss: 0.0246 - val_acc: 0.9930\n",
      "Epoch 7/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0084 - acc: 0.9969 - val_loss: 0.0338 - val_acc: 0.9921\n",
      "Epoch 8/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0064 - acc: 0.9978 - val_loss: 0.0269 - val_acc: 0.9930\n",
      "Epoch 1/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0044 - acc: 0.9985 - val_loss: 0.0340 - val_acc: 0.9923\n",
      "Epoch 2/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0052 - acc: 0.9982 - val_loss: 0.0238 - val_acc: 0.9939\n",
      "Epoch 3/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0037 - acc: 0.9987 - val_loss: 0.0268 - val_acc: 0.9930\n",
      "Epoch 4/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0042 - acc: 0.9986 - val_loss: 0.0246 - val_acc: 0.9936\n",
      "Epoch 5/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0041 - acc: 0.9985 - val_loss: 0.0326 - val_acc: 0.9917\n",
      "Epoch 6/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0056 - acc: 0.9982 - val_loss: 0.0293 - val_acc: 0.9933\n",
      "Epoch 7/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0041 - acc: 0.9986 - val_loss: 0.0250 - val_acc: 0.9939\n",
      "Epoch 8/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0040 - acc: 0.9988 - val_loss: 0.0352 - val_acc: 0.9916\n",
      "Epoch 1/8\n",
      "234/234 [==============================] - 9s 38ms/step - loss: 0.1355 - acc: 0.9606 - val_loss: 0.0366 - val_acc: 0.9877\n",
      "Epoch 2/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0394 - acc: 0.9880 - val_loss: 0.0271 - val_acc: 0.9921\n",
      "Epoch 3/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0251 - acc: 0.9920 - val_loss: 0.0241 - val_acc: 0.9921\n",
      "Epoch 4/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0192 - acc: 0.9940 - val_loss: 0.0266 - val_acc: 0.9919\n",
      "Epoch 5/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0163 - acc: 0.9943 - val_loss: 0.0289 - val_acc: 0.9915\n",
      "Epoch 6/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0159 - acc: 0.9949 - val_loss: 0.0236 - val_acc: 0.9922\n",
      "Epoch 7/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0123 - acc: 0.9959 - val_loss: 0.0242 - val_acc: 0.9933\n",
      "Epoch 8/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0100 - acc: 0.9968 - val_loss: 0.0306 - val_acc: 0.9901\n",
      "Epoch 1/4\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0097 - acc: 0.9969 - val_loss: 0.0265 - val_acc: 0.9921\n",
      "Epoch 2/4\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0098 - acc: 0.9969 - val_loss: 0.0350 - val_acc: 0.9904\n",
      "Epoch 3/4\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0103 - acc: 0.9965 - val_loss: 0.0244 - val_acc: 0.9931\n",
      "Epoch 4/4\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0063 - acc: 0.9978 - val_loss: 0.0237 - val_acc: 0.9931\n",
      "Epoch 1/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0068 - acc: 0.9977 - val_loss: 0.0263 - val_acc: 0.9937\n",
      "Epoch 2/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0080 - acc: 0.9973 - val_loss: 0.0295 - val_acc: 0.9925\n",
      "Epoch 3/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0079 - acc: 0.9972 - val_loss: 0.0348 - val_acc: 0.9906\n",
      "Epoch 4/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0060 - acc: 0.9979 - val_loss: 0.0349 - val_acc: 0.9907\n",
      "Epoch 5/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0052 - acc: 0.9983 - val_loss: 0.0268 - val_acc: 0.9934\n",
      "Epoch 6/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0059 - acc: 0.9980 - val_loss: 0.0293 - val_acc: 0.9925\n",
      "Epoch 7/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0072 - acc: 0.9975 - val_loss: 0.0288 - val_acc: 0.9936\n",
      "Epoch 8/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0057 - acc: 0.9981 - val_loss: 0.0274 - val_acc: 0.9928\n",
      "Epoch 1/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0045 - acc: 0.9985 - val_loss: 0.0303 - val_acc: 0.9924\n",
      "Epoch 2/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0036 - acc: 0.9987 - val_loss: 0.0233 - val_acc: 0.9942\n",
      "Epoch 3/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0050 - acc: 0.9981 - val_loss: 0.0428 - val_acc: 0.9897\n",
      "Epoch 4/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0065 - acc: 0.9977 - val_loss: 0.0278 - val_acc: 0.9936\n",
      "Epoch 5/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0067 - acc: 0.9979 - val_loss: 0.0369 - val_acc: 0.9908\n",
      "Epoch 6/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0046 - acc: 0.9985 - val_loss: 0.0346 - val_acc: 0.9919\n",
      "Epoch 7/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0038 - acc: 0.9988 - val_loss: 0.0304 - val_acc: 0.9927\n",
      "Epoch 8/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0031 - acc: 0.9989 - val_loss: 0.0370 - val_acc: 0.9934\n",
      "Epoch 1/8\n",
      "234/234 [==============================] - 9s 40ms/step - loss: 0.1337 - acc: 0.9609 - val_loss: 0.0443 - val_acc: 0.9873\n",
      "Epoch 2/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0402 - acc: 0.9873 - val_loss: 0.0343 - val_acc: 0.9889\n",
      "Epoch 3/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0264 - acc: 0.9916 - val_loss: 0.0368 - val_acc: 0.9897\n",
      "Epoch 4/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0196 - acc: 0.9937 - val_loss: 0.0247 - val_acc: 0.9925\n",
      "Epoch 5/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0165 - acc: 0.9944 - val_loss: 0.0265 - val_acc: 0.9916\n",
      "Epoch 6/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0152 - acc: 0.9949 - val_loss: 0.0290 - val_acc: 0.9906\n",
      "Epoch 7/8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0119 - acc: 0.9962 - val_loss: 0.0285 - val_acc: 0.9916\n",
      "Epoch 8/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0110 - acc: 0.9963 - val_loss: 0.0472 - val_acc: 0.9872\n",
      "Epoch 1/4\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0111 - acc: 0.9963 - val_loss: 0.0316 - val_acc: 0.9913\n",
      "Epoch 2/4\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0085 - acc: 0.9971 - val_loss: 0.0246 - val_acc: 0.9930\n",
      "Epoch 3/4\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0085 - acc: 0.9970 - val_loss: 0.0300 - val_acc: 0.9910\n",
      "Epoch 4/4\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0061 - acc: 0.9979 - val_loss: 0.0316 - val_acc: 0.9913\n",
      "Epoch 1/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0076 - acc: 0.9974 - val_loss: 0.0300 - val_acc: 0.9911\n",
      "Epoch 2/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0081 - acc: 0.9972 - val_loss: 0.0298 - val_acc: 0.9920\n",
      "Epoch 3/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0066 - acc: 0.9976 - val_loss: 0.0316 - val_acc: 0.9915\n",
      "Epoch 4/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0051 - acc: 0.9983 - val_loss: 0.0328 - val_acc: 0.9918\n",
      "Epoch 5/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0053 - acc: 0.9982 - val_loss: 0.0335 - val_acc: 0.9917\n",
      "Epoch 6/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0065 - acc: 0.9978 - val_loss: 0.0329 - val_acc: 0.9911\n",
      "Epoch 7/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0076 - acc: 0.9974 - val_loss: 0.0330 - val_acc: 0.9921\n",
      "Epoch 8/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0048 - acc: 0.9982 - val_loss: 0.0286 - val_acc: 0.9928\n",
      "Epoch 1/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0028 - acc: 0.9992 - val_loss: 0.0297 - val_acc: 0.9930\n",
      "Epoch 2/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0029 - acc: 0.9990 - val_loss: 0.0332 - val_acc: 0.9913\n",
      "Epoch 3/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0044 - acc: 0.9986 - val_loss: 0.0430 - val_acc: 0.9898\n",
      "Epoch 4/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0081 - acc: 0.9973 - val_loss: 0.0376 - val_acc: 0.9912\n",
      "Epoch 5/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0062 - acc: 0.9979 - val_loss: 0.0273 - val_acc: 0.9924\n",
      "Epoch 6/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0041 - acc: 0.9985 - val_loss: 0.0279 - val_acc: 0.9925\n",
      "Epoch 7/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0054 - acc: 0.9982 - val_loss: 0.0317 - val_acc: 0.9920\n",
      "Epoch 8/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0049 - acc: 0.9983 - val_loss: 0.0321 - val_acc: 0.9929\n",
      "Epoch 1/8\n",
      "234/234 [==============================] - 10s 43ms/step - loss: 0.1344 - acc: 0.9596 - val_loss: 0.0331 - val_acc: 0.9890\n",
      "Epoch 2/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0377 - acc: 0.9886 - val_loss: 0.0297 - val_acc: 0.9911\n",
      "Epoch 3/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0258 - acc: 0.9918 - val_loss: 0.0278 - val_acc: 0.9917\n",
      "Epoch 4/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0186 - acc: 0.9940 - val_loss: 0.0280 - val_acc: 0.9916\n",
      "Epoch 5/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0157 - acc: 0.9952 - val_loss: 0.0238 - val_acc: 0.9931\n",
      "Epoch 6/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0109 - acc: 0.9965 - val_loss: 0.0220 - val_acc: 0.9926\n",
      "Epoch 7/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0120 - acc: 0.9957 - val_loss: 0.0316 - val_acc: 0.9909\n",
      "Epoch 8/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0120 - acc: 0.9959 - val_loss: 0.0256 - val_acc: 0.9930\n",
      "Epoch 1/4\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0098 - acc: 0.9965 - val_loss: 0.0272 - val_acc: 0.9912\n",
      "Epoch 2/4\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0110 - acc: 0.9963 - val_loss: 0.0279 - val_acc: 0.9915\n",
      "Epoch 3/4\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0079 - acc: 0.9972 - val_loss: 0.0264 - val_acc: 0.9930\n",
      "Epoch 4/4\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0067 - acc: 0.9980 - val_loss: 0.0267 - val_acc: 0.9931\n",
      "Epoch 1/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0055 - acc: 0.9980 - val_loss: 0.0234 - val_acc: 0.9929\n",
      "Epoch 2/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0043 - acc: 0.9986 - val_loss: 0.0303 - val_acc: 0.9921\n",
      "Epoch 3/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0089 - acc: 0.9969 - val_loss: 0.0222 - val_acc: 0.9932\n",
      "Epoch 4/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0076 - acc: 0.9973 - val_loss: 0.0370 - val_acc: 0.9898\n",
      "Epoch 5/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0077 - acc: 0.9975 - val_loss: 0.0259 - val_acc: 0.9945\n",
      "Epoch 6/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0054 - acc: 0.9984 - val_loss: 0.0259 - val_acc: 0.9946\n",
      "Epoch 7/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0044 - acc: 0.9985 - val_loss: 0.0233 - val_acc: 0.9949\n",
      "Epoch 8/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0053 - acc: 0.9983 - val_loss: 0.0346 - val_acc: 0.9916\n",
      "Epoch 1/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0047 - acc: 0.9983 - val_loss: 0.0359 - val_acc: 0.9914\n",
      "Epoch 2/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0048 - acc: 0.9982 - val_loss: 0.0352 - val_acc: 0.9922\n",
      "Epoch 3/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0051 - acc: 0.9984 - val_loss: 0.0321 - val_acc: 0.9924\n",
      "Epoch 4/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0057 - acc: 0.9980 - val_loss: 0.0249 - val_acc: 0.9936\n",
      "Epoch 5/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0060 - acc: 0.9980 - val_loss: 0.0345 - val_acc: 0.9920\n",
      "Epoch 6/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0040 - acc: 0.9986 - val_loss: 0.0293 - val_acc: 0.9926\n",
      "Epoch 7/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0036 - acc: 0.9988 - val_loss: 0.0253 - val_acc: 0.9939\n",
      "Epoch 8/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0039 - acc: 0.9987 - val_loss: 0.0282 - val_acc: 0.9941\n",
      "Epoch 1/8\n",
      "234/234 [==============================] - 11s 45ms/step - loss: 0.1368 - acc: 0.9593 - val_loss: 0.0404 - val_acc: 0.9873\n",
      "Epoch 2/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0401 - acc: 0.9875 - val_loss: 0.0332 - val_acc: 0.9888\n",
      "Epoch 3/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0266 - acc: 0.9919 - val_loss: 0.0326 - val_acc: 0.9894\n",
      "Epoch 4/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0201 - acc: 0.9937 - val_loss: 0.0307 - val_acc: 0.9899\n",
      "Epoch 5/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0173 - acc: 0.9942 - val_loss: 0.0207 - val_acc: 0.9929\n",
      "Epoch 6/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0148 - acc: 0.9948 - val_loss: 0.0263 - val_acc: 0.9914\n",
      "Epoch 7/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0136 - acc: 0.9956 - val_loss: 0.0288 - val_acc: 0.9913\n",
      "Epoch 8/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0099 - acc: 0.9966 - val_loss: 0.0289 - val_acc: 0.9922\n",
      "Epoch 1/4\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0083 - acc: 0.9973 - val_loss: 0.0248 - val_acc: 0.9932\n",
      "Epoch 2/4\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0085 - acc: 0.9972 - val_loss: 0.0244 - val_acc: 0.9932\n",
      "Epoch 3/4\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0097 - acc: 0.9968 - val_loss: 0.0310 - val_acc: 0.9921\n",
      "Epoch 4/4\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0082 - acc: 0.9972 - val_loss: 0.0278 - val_acc: 0.9930\n",
      "Epoch 1/8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0085 - acc: 0.9970 - val_loss: 0.0280 - val_acc: 0.9922\n",
      "Epoch 2/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0079 - acc: 0.9974 - val_loss: 0.0268 - val_acc: 0.9918\n",
      "Epoch 3/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0056 - acc: 0.9982 - val_loss: 0.0218 - val_acc: 0.9941\n",
      "Epoch 4/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0047 - acc: 0.9984 - val_loss: 0.0281 - val_acc: 0.9929\n",
      "Epoch 5/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0068 - acc: 0.9977 - val_loss: 0.0364 - val_acc: 0.9908\n",
      "Epoch 6/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0090 - acc: 0.9970 - val_loss: 0.0466 - val_acc: 0.9886\n",
      "Epoch 7/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0070 - acc: 0.9975 - val_loss: 0.0264 - val_acc: 0.9929\n",
      "Epoch 8/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0043 - acc: 0.9986 - val_loss: 0.0239 - val_acc: 0.9933\n",
      "Epoch 1/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0057 - acc: 0.9982 - val_loss: 0.0286 - val_acc: 0.9930\n",
      "Epoch 2/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0045 - acc: 0.9986 - val_loss: 0.0300 - val_acc: 0.9927\n",
      "Epoch 3/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0047 - acc: 0.9984 - val_loss: 0.0276 - val_acc: 0.9928\n",
      "Epoch 4/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0047 - acc: 0.9984 - val_loss: 0.0274 - val_acc: 0.9929\n",
      "Epoch 5/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0045 - acc: 0.9985 - val_loss: 0.0307 - val_acc: 0.9926\n",
      "Epoch 6/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0052 - acc: 0.9983 - val_loss: 0.0342 - val_acc: 0.9910\n",
      "Epoch 7/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0059 - acc: 0.9980 - val_loss: 0.0313 - val_acc: 0.9927\n",
      "Epoch 8/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0045 - acc: 0.9985 - val_loss: 0.0235 - val_acc: 0.9932\n",
      "Epoch 1/8\n",
      "234/234 [==============================] - 11s 48ms/step - loss: 0.1439 - acc: 0.9584 - val_loss: 0.0403 - val_acc: 0.9867\n",
      "Epoch 2/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0395 - acc: 0.9878 - val_loss: 0.0406 - val_acc: 0.9877\n",
      "Epoch 3/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0274 - acc: 0.9913 - val_loss: 0.0259 - val_acc: 0.9915\n",
      "Epoch 4/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0206 - acc: 0.9934 - val_loss: 0.0295 - val_acc: 0.9913\n",
      "Epoch 5/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0157 - acc: 0.9952 - val_loss: 0.0270 - val_acc: 0.9920\n",
      "Epoch 6/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0135 - acc: 0.9955 - val_loss: 0.0330 - val_acc: 0.9899\n",
      "Epoch 7/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0124 - acc: 0.9958 - val_loss: 0.0266 - val_acc: 0.9913\n",
      "Epoch 8/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0121 - acc: 0.9961 - val_loss: 0.0231 - val_acc: 0.9942\n",
      "Epoch 1/4\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0087 - acc: 0.9974 - val_loss: 0.0248 - val_acc: 0.9923\n",
      "Epoch 2/4\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0073 - acc: 0.9978 - val_loss: 0.0230 - val_acc: 0.9929\n",
      "Epoch 3/4\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0089 - acc: 0.9971 - val_loss: 0.0275 - val_acc: 0.9925\n",
      "Epoch 4/4\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0098 - acc: 0.9967 - val_loss: 0.0312 - val_acc: 0.9917\n",
      "Epoch 1/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0075 - acc: 0.9976 - val_loss: 0.0226 - val_acc: 0.9930\n",
      "Epoch 2/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0062 - acc: 0.9981 - val_loss: 0.0330 - val_acc: 0.9920\n",
      "Epoch 3/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0069 - acc: 0.9976 - val_loss: 0.0218 - val_acc: 0.9941\n",
      "Epoch 4/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0082 - acc: 0.9971 - val_loss: 0.0315 - val_acc: 0.9918\n",
      "Epoch 5/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0076 - acc: 0.9974 - val_loss: 0.0320 - val_acc: 0.9921\n",
      "Epoch 6/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0059 - acc: 0.9979 - val_loss: 0.0345 - val_acc: 0.9919\n",
      "Epoch 7/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0073 - acc: 0.9976 - val_loss: 0.0290 - val_acc: 0.9926\n",
      "Epoch 8/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0051 - acc: 0.9984 - val_loss: 0.0253 - val_acc: 0.9931\n",
      "Epoch 1/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0048 - acc: 0.9983 - val_loss: 0.0313 - val_acc: 0.9936\n",
      "Epoch 2/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0049 - acc: 0.9984 - val_loss: 0.0290 - val_acc: 0.9937\n",
      "Epoch 3/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0041 - acc: 0.9985 - val_loss: 0.0333 - val_acc: 0.9921\n",
      "Epoch 4/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0061 - acc: 0.9979 - val_loss: 0.0272 - val_acc: 0.9926\n",
      "Epoch 5/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0071 - acc: 0.9977 - val_loss: 0.0364 - val_acc: 0.9905\n",
      "Epoch 6/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0051 - acc: 0.9985 - val_loss: 0.0293 - val_acc: 0.9925\n",
      "Epoch 7/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0038 - acc: 0.9987 - val_loss: 0.0371 - val_acc: 0.9917\n",
      "Epoch 8/8\n",
      "234/234 [==============================] - 7s 31ms/step - loss: 0.0047 - acc: 0.9984 - val_loss: 0.0315 - val_acc: 0.9929\n"
     ]
    }
   ],
   "source": [
    "models = [fit_model() for i in range(6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME_DIR = os.getenv('HOME')\n",
    "path = HOME_DIR + '/data/mnist/'\n",
    "model_path = path + 'models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, m in enumerate(models):\n",
    "    m.save_weights(model_path+'cnn-mnist-'+str(i)+'.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 46us/step\n",
      "10000/10000 [==============================] - 0s 44us/step\n",
      "10000/10000 [==============================] - 0s 44us/step\n",
      "10000/10000 [==============================] - 0s 44us/step\n",
      "10000/10000 [==============================] - 0s 44us/step\n",
      "10000/10000 [==============================] - 0s 44us/step\n"
     ]
    }
   ],
   "source": [
    "evals = np.array([m.evaluate(X_test, y_test, batch_size=256) for m in models])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03120511, 0.99301667])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evals.mean(axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = np.stack([m.predict(X_test, batch_size=256) for m in models])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 10), (10000, 10))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_preds.shape\n",
    "avg_preds = all_preds.mean(axis=0).astype(np.float64)\n",
    "avg_preds.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras metric function takes (y_true, y_pred)\n",
    "# it returns array of size [n_samples] with interger values in [0, 1]\n",
    "# need to do eval() and mean() to get the accuracy over the whole set\n",
    "# need a tensorflow session to make this work:\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    ensemble_acc = keras.metrics.categorical_accuracy(\n",
    "        y_test, avg_preds).eval().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((), (10000, 10), (10000, 10))\n",
      "(array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]), array([1.42073757e-11, 5.86463586e-11, 1.51004972e-11, 6.81085813e-11,\n",
      "       3.10937075e-11, 8.37415803e-14, 6.46788641e-15, 1.00000000e+00,\n",
      "       1.32774422e-14, 4.71349765e-11]))\n",
      "(dtype('float64'), dtype('float64'))\n",
      "0.9952\n"
     ]
    }
   ],
   "source": [
    "print(ensemble_acc.shape, avg_preds.shape, y_test.shape)\n",
    "print(y_test[0,:], avg_preds[0,:])\n",
    "print(y_test.dtype, avg_preds.dtype)\n",
    "print(ensemble_acc)\n",
    "# https://stackoverflow.com/questions/40768313/tensorflow-eval-without-session-or-move-variable-to-an-other-session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: TRAIN FOR LONGER TIME AND PARAM SEARCH"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
