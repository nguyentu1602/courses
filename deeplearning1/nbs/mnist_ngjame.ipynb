{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End-to-end MNIST training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n",
      "Using cuDNN version 6021 on context None\n",
      "Mapped name None to device cuda: GeForce GTX 960 (0000:01:00.0)\n",
      "/home/nguyentu/anaconda3/envs/py27_tf_cv/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import utils; reload(utils); # init theano GPU\n",
    "from utils import *\n",
    "from __future__ import division, print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SETUP \n",
    "batch_size = 256 # MNIST data is small, so my computer can surely handle this\n",
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST contains grayscale images, so we need to expand a dim\n",
    "# so that we got data in shape: (n_samples, n_channels, h, w)\n",
    "X_test = np.expand_dims(X_test, 1) # second dimension\n",
    "X_train = np.expand_dims(X_train, 1) # second dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 1, 28, 28), (10000, 1, 28, 28), dtype('uint8'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, X_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1, 9], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5] # see what categories we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "??onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "??to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert y to onehot encoding\n",
    "y_train = onehot(y_train)\n",
    "y_test = onehot(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# normalize the input\n",
    "print(X_train.shape)\n",
    "mean_px = X_train.mean().astype(np.float32)\n",
    "std_px = X_train.std().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_input(x): return (x - mean_px)/std_px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LINEAR MODEL\n",
    "def get_lin_model():\n",
    "    \"\"\"This is ensentially a multi-output linear model\"\"\"\n",
    "    model = Sequential([\n",
    "        Lambda(norm_input, input_shape = (1, 28, 28)),\n",
    "        Flatten(),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "    model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nguyentu/anaconda3/envs/py27_tf_cv/lib/python2.7/site-packages/keras/layers/core.py:630: UserWarning: `output_shape` argument not specified for layer lambda_1 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 1, 28, 28)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    }
   ],
   "source": [
    "lm = get_lin_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000, 235, 40)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make keras' numpyArrayIterator\n",
    "gen = image.ImageDataGenerator()\n",
    "batches = gen.flow(X_train, y_train, batch_size=batch_size)\n",
    "test_batches = gen.flow(X_test, y_test, batch_size=batch_size)\n",
    "\n",
    "# new keras params:\n",
    "# steps_per_epoch: Total number of steps (batches of samples) \n",
    "# before declaring one epoch finished and starting the next\n",
    "# epoch.  similar for validation_steps\n",
    "steps_per_epoch = int(np.ceil(batches.n/batch_size))\n",
    "validation_steps = int(np.ceil(test_batches.n/batch_size))\n",
    "\n",
    "(batches.n, test_batches.n, steps_per_epoch, validation_steps) # show dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-0affda2b62ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# to start, use default learning rate for 1 epoch and see what you get\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# for linear model, we get 91% acc, not really great\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m lm.fit_generator(batches, steps_per_epoch=steps_per_epoch,\n\u001b[0m\u001b[1;32m      5\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_batches\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lm' is not defined"
     ]
    }
   ],
   "source": [
    "# fitting data:\n",
    "# to start, use default learning rate for 1 epoch and see what you get\n",
    "# for linear model, we get 91% acc, not really great  \n",
    "lm.fit_generator(batches, steps_per_epoch=steps_per_epoch,\n",
    "                    epochs=1, \n",
    "                    validation_data=test_batches, \n",
    "                    validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SINGLE DENSE LAYER\n",
    "def get_fc_model():\n",
    "    \"\"\"Add a fully-connected hidden layer. Old school.\"\"\"\n",
    "    model = Sequential([\n",
    "        Lambda(norm_input, input_shape=(1, 28, 28)),\n",
    "        Flatten(),\n",
    "        Dense(1024, activation='softmax'),\n",
    "        Dense(10, activation='softmax')\n",
    "        ])\n",
    "    model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nguyentu/anaconda3/envs/py27_tf_cv/lib/python2.7/site-packages/keras/layers/core.py:630: UserWarning: `output_shape` argument not specified for layer lambda_1 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 1, 28, 28)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 2.0242 - acc: 0.8159 - val_loss: 1.7901 - val_acc: 0.9173\n",
      "Epoch 2/8\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 1.6079 - acc: 0.9199 - val_loss: 1.4277 - val_acc: 0.9235\n",
      "Epoch 3/8\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 1.2784 - acc: 0.9250 - val_loss: 1.1325 - val_acc: 0.9272\n",
      "Epoch 4/8\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 1.0207 - acc: 0.9280 - val_loss: 0.9124 - val_acc: 0.9285\n",
      "Epoch 5/8\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.8293 - acc: 0.9313 - val_loss: 0.7534 - val_acc: 0.9298\n",
      "Epoch 6/8\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.6881 - acc: 0.9347 - val_loss: 0.6348 - val_acc: 0.9314\n",
      "Epoch 7/8\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.5848 - acc: 0.9363 - val_loss: 0.5511 - val_acc: 0.9314\n",
      "Epoch 8/8\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.5083 - acc: 0.9388 - val_loss: 0.4868 - val_acc: 0.9333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0fe3214710>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc = get_fc_model()\n",
    "# With 8 training epochs, I got 93% validation accuracy\n",
    "# pretty good\n",
    "fc.fit_generator(batches, epochs=8, \n",
    "                 steps_per_epoch=steps_per_epoch,\n",
    "                 validation_steps=validation_steps, \n",
    "                 validation_data=test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASIC VGG-STYLE CNN\n",
    "def get_model():\n",
    "    model = Sequential([\n",
    "        Lambda(norm_input, input_shape=(1, 28, 28)),\n",
    "        Convolution2D(32, 3, 3, activation='relu'),\n",
    "        Convolution2D(32, 3, 3, activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Convolution2D(64, 3, 3, activation='relu'),\n",
    "        Convolution2D(64, 3, 3, activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "    model.compile(Adam(), loss='categorical_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nguyentu/anaconda3/envs/py27_tf_cv/lib/python2.7/site-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
      "  \"\"\"\n",
      "/home/nguyentu/anaconda3/envs/py27_tf_cv/lib/python2.7/site-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
      "  \n",
      "/home/nguyentu/anaconda3/envs/py27_tf_cv/lib/python2.7/site-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "  \n",
      "/home/nguyentu/anaconda3/envs/py27_tf_cv/lib/python2.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "  if __name__ == '__main__':\n",
      "/home/nguyentu/anaconda3/envs/py27_tf_cv/lib/python2.7/site-packages/keras/layers/core.py:630: UserWarning: `output_shape` argument not specified for layer lambda_2 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 1, 28, 28)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    }
   ],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "235/235 [==============================] - 9s 39ms/step - loss: 0.1768 - acc: 0.9472 - val_loss: 0.0432 - val_acc: 0.9854\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0f9c4c5e10>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(batches, epochs=1,\n",
    "                steps_per_epoch=steps_per_epoch,\n",
    "                validation_steps=validation_steps, \n",
    "                validation_data=test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change learning rate\n",
    "model.optimizer.lr=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "235/235 [==============================] - 9s 39ms/step - loss: 0.0434 - acc: 0.9870 - val_loss: 0.0298 - val_acc: 0.9898\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0f9b56e1d0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(batches, epochs=1,\n",
    "                steps_per_epoch=steps_per_epoch,\n",
    "                validation_steps=validation_steps, \n",
    "                validation_data=test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "235/235 [==============================] - 9s 39ms/step - loss: 0.0289 - acc: 0.9911 - val_loss: 0.0245 - val_acc: 0.9913\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0f9bd72610>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one more epoch - we overfitted this time\n",
    "model.optimizer.lr = 0.05\n",
    "model.fit_generator(batches, epochs=1,\n",
    "                steps_per_epoch=steps_per_epoch,\n",
    "                validation_steps=validation_steps, \n",
    "                validation_data=test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nguyentu/anaconda3/envs/py27_tf_cv/lib/python2.7/site-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
      "  \"\"\"\n",
      "/home/nguyentu/anaconda3/envs/py27_tf_cv/lib/python2.7/site-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
      "  \n",
      "/home/nguyentu/anaconda3/envs/py27_tf_cv/lib/python2.7/site-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "  \n",
      "/home/nguyentu/anaconda3/envs/py27_tf_cv/lib/python2.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "  if __name__ == '__main__':\n",
      "/home/nguyentu/anaconda3/envs/py27_tf_cv/lib/python2.7/site-packages/keras/layers/core.py:630: UserWarning: `output_shape` argument not specified for layer lambda_3 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 1, 28, 28)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    }
   ],
   "source": [
    "# DATA AUGMENTATION\n",
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = image.ImageDataGenerator(rotation_range=8, width_shift_range=0.08,\n",
    "                              height_shift_range=0.08, zoom_range=0.08)\n",
    "batches = gen.flow(X_train, y_train, batch_size=64)\n",
    "test_batches = gen.flow(X_test, y_test, batch_size=64)\n",
    "\n",
    "steps_per_epoch = int(np.ceil(batches.n/batch_size))\n",
    "validation_steps = int(np.ceil(test_batches.n/batch_size))\n",
    "\n",
    "# TODO: visualize data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "235/235 [==============================] - 4s 15ms/step - loss: 0.1171 - acc: 0.9641 - val_loss: 0.1025 - val_acc: 0.9688\n",
      "Epoch 2/4\n",
      "235/235 [==============================] - 3s 14ms/step - loss: 0.0947 - acc: 0.9699 - val_loss: 0.0694 - val_acc: 0.9789\n",
      "Epoch 3/4\n",
      "235/235 [==============================] - 3s 14ms/step - loss: 0.0684 - acc: 0.9805 - val_loss: 0.0530 - val_acc: 0.9824\n",
      "Epoch 4/4\n",
      "235/235 [==============================] - 4s 15ms/step - loss: 0.0660 - acc: 0.9803 - val_loss: 0.0771 - val_acc: 0.9785\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0ff671aed0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(batches, epochs=4,\n",
    "                steps_per_epoch=steps_per_epoch,\n",
    "                validation_steps=validation_steps, \n",
    "                validation_data=test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH NORM\n",
    "def get_model_bn():\n",
    "    model = Sequential([\n",
    "        Lambda(norm_input, input_shape=(1, 28, 28)),\n",
    "        Convolution2D(32, 3, 3, activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Convolution2D(32, 3, 3, activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        BatchNormalization(axis=1),\n",
    "        Convolution2D(64, 3, 3, activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Convolution2D(64, 3, 3, activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        BatchNormalization(),\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "    model.compile(Adam(), loss='categorical_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# TODO: WHY DO WE NEED AXIS=1 for batchnorm in Conv layers?\n",
    "# solution is on the forum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nguyentu/anaconda3/envs/py27_tf_cv/lib/python2.7/site-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
      "  \"\"\"\n",
      "/home/nguyentu/anaconda3/envs/py27_tf_cv/lib/python2.7/site-packages/ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
      "  import sys\n",
      "/home/nguyentu/anaconda3/envs/py27_tf_cv/lib/python2.7/site-packages/ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/nguyentu/anaconda3/envs/py27_tf_cv/lib/python2.7/site-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "  if sys.path[0] == '':\n",
      "/home/nguyentu/anaconda3/envs/py27_tf_cv/lib/python2.7/site-packages/keras/layers/core.py:630: UserWarning: `output_shape` argument not specified for layer lambda_5 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 1, 28, 28)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    }
   ],
   "source": [
    "model_bn = get_model_bn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.1057 - acc: 0.9668 - val_loss: 0.2374 - val_acc: 0.9203\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0f86c0d0d0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start with default learning rate first\n",
    "model_bn.fit_generator(batches, epochs=1,\n",
    "                steps_per_epoch=steps_per_epoch,\n",
    "                validation_steps=validation_steps, \n",
    "                validation_data=test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bn.optimizer.lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0809 - acc: 0.9757 - val_loss: 0.0892 - val_acc: 0.9746\n",
      "Epoch 2/4\n",
      "235/235 [==============================] - 5s 23ms/step - loss: 0.0787 - acc: 0.9753 - val_loss: 0.0644 - val_acc: 0.9785\n",
      "Epoch 3/4\n",
      "235/235 [==============================] - 5s 23ms/step - loss: 0.0688 - acc: 0.9772 - val_loss: 0.0432 - val_acc: 0.9848\n",
      "Epoch 4/4\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0629 - acc: 0.9804 - val_loss: 0.0736 - val_acc: 0.9801\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0ffbd8c650>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bn.fit_generator(batches, epochs=4,\n",
    "                steps_per_epoch=steps_per_epoch,\n",
    "                validation_steps=validation_steps, \n",
    "                validation_data=test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bn.optimizer.lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0580 - acc: 0.9820 - val_loss: 0.0596 - val_acc: 0.9812\n",
      "Epoch 2/4\n",
      "235/235 [==============================] - 5s 23ms/step - loss: 0.0604 - acc: 0.9815 - val_loss: 0.0466 - val_acc: 0.9875\n",
      "Epoch 3/4\n",
      "235/235 [==============================] - 5s 23ms/step - loss: 0.0533 - acc: 0.9829 - val_loss: 0.0663 - val_acc: 0.9840\n",
      "Epoch 4/4\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0559 - acc: 0.9819 - val_loss: 0.0546 - val_acc: 0.9805\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0f8bd4dfd0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bn.fit_generator(batches, epochs=4,\n",
    "                steps_per_epoch=steps_per_epoch,\n",
    "                validation_steps=validation_steps, \n",
    "                validation_data=test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bn.optimizer.lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bn.fit_generator(batches, epochs=8,\n",
    "                steps_per_epoch=steps_per_epoch,\n",
    "                validation_steps=validation_steps, \n",
    "                validation_data=test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCHNORM + DROPOUT + DATA AUGMENTATION\n",
    "# Combine all the good stuff so far\n",
    "def get_model_bn_do():\n",
    "    model = Sequential([\n",
    "        Lambda(norm_input, input_shape=(1, 28, 28)),\n",
    "        Convolution2D(32, 3, 3, activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Convolution2D(32, 3, 3, activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        BatchNormalization(axis=1),\n",
    "        Convolution2D(64, 3, 3, activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Convolution2D(64, 3, 3, activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        BatchNormalization(),\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "    model.compile(Adam(), loss='categorical_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nguyentu/anaconda3/envs/py27_tf_cv/lib/python2.7/site-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
      "  \n",
      "/home/nguyentu/anaconda3/envs/py27_tf_cv/lib/python2.7/site-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
      "  \n",
      "/home/nguyentu/anaconda3/envs/py27_tf_cv/lib/python2.7/site-packages/ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/nguyentu/anaconda3/envs/py27_tf_cv/lib/python2.7/site-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "  del sys.path[0]\n",
      "/home/nguyentu/anaconda3/envs/py27_tf_cv/lib/python2.7/site-packages/keras/layers/core.py:630: UserWarning: `output_shape` argument not specified for layer lambda_7 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 1, 28, 28)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    }
   ],
   "source": [
    "model_bn_do = get_model_bn_do()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0475 - acc: 0.9858 - val_loss: 0.0296 - val_acc: 0.9906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0f51151590>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# should ALWAYS use the default learning rates for a couple of epoch\n",
    "model_bn_do.fit_generator(batches, epochs=1,\n",
    "                steps_per_epoch=steps_per_epoch,\n",
    "                validation_steps=validation_steps, \n",
    "                validation_data=test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.1633 - acc: 0.9491 - val_loss: 0.2016 - val_acc: 0.9391\n",
      "Epoch 2/4\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.1192 - acc: 0.9621 - val_loss: 0.0690 - val_acc: 0.9777\n",
      "Epoch 3/4\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.0986 - acc: 0.9695 - val_loss: 0.0738 - val_acc: 0.9801\n",
      "Epoch 4/4\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0924 - acc: 0.9725 - val_loss: 0.0704 - val_acc: 0.9781\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0f7db87e50>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bn_do.optimizer.lr = 0.1 # shift-M to merge in command mode\n",
    "model_bn_do.fit_generator(batches, epochs=4,\n",
    "                steps_per_epoch=steps_per_epoch,\n",
    "                validation_steps=validation_steps, \n",
    "                validation_data=test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0887 - acc: 0.9726 - val_loss: 0.0529 - val_acc: 0.9855\n",
      "Epoch 2/8\n",
      "235/235 [==============================] - 5s 23ms/step - loss: 0.0811 - acc: 0.9737 - val_loss: 0.0658 - val_acc: 0.9797\n",
      "Epoch 3/8\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.0783 - acc: 0.9753 - val_loss: 0.0821 - val_acc: 0.9754\n",
      "Epoch 4/8\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0726 - acc: 0.9782 - val_loss: 0.0339 - val_acc: 0.9898\n",
      "Epoch 5/8\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.0656 - acc: 0.9805 - val_loss: 0.0501 - val_acc: 0.9859\n",
      "Epoch 6/8\n",
      "235/235 [==============================] - 5s 23ms/step - loss: 0.0625 - acc: 0.9800 - val_loss: 0.0410 - val_acc: 0.9883\n",
      "Epoch 7/8\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.0571 - acc: 0.9831 - val_loss: 0.0416 - val_acc: 0.9852\n",
      "Epoch 8/8\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0623 - acc: 0.9804 - val_loss: 0.0412 - val_acc: 0.9875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0f7d43add0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bn_do.optimizer.lr = 0.01 # shift-M to merge in command mode\n",
    "model_bn_do.fit_generator(batches, epochs=8,\n",
    "                steps_per_epoch=steps_per_epoch,\n",
    "                validation_steps=validation_steps, \n",
    "                validation_data=test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0491 - acc: 0.9853 - val_loss: 0.0270 - val_acc: 0.9918\n",
      "Epoch 2/12\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.0574 - acc: 0.9827 - val_loss: 0.0300 - val_acc: 0.9910\n",
      "Epoch 3/12\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.0518 - acc: 0.9846 - val_loss: 0.0307 - val_acc: 0.9895\n",
      "Epoch 4/12\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0451 - acc: 0.9863 - val_loss: 0.0402 - val_acc: 0.9875\n",
      "Epoch 5/12\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.0444 - acc: 0.9855 - val_loss: 0.0343 - val_acc: 0.9898\n",
      "Epoch 6/12\n",
      "235/235 [==============================] - 5s 23ms/step - loss: 0.0471 - acc: 0.9856 - val_loss: 0.0337 - val_acc: 0.9906\n",
      "Epoch 7/12\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.0444 - acc: 0.9862 - val_loss: 0.0335 - val_acc: 0.9887\n",
      "Epoch 8/12\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0457 - acc: 0.9860 - val_loss: 0.0305 - val_acc: 0.9883\n",
      "Epoch 9/12\n",
      "235/235 [==============================] - 5s 23ms/step - loss: 0.0405 - acc: 0.9868 - val_loss: 0.0405 - val_acc: 0.9879\n",
      "Epoch 10/12\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.0452 - acc: 0.9857 - val_loss: 0.0237 - val_acc: 0.9945\n",
      "Epoch 11/12\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.0390 - acc: 0.9873 - val_loss: 0.0285 - val_acc: 0.9930\n",
      "Epoch 12/12\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0419 - acc: 0.9878 - val_loss: 0.0350 - val_acc: 0.9871\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0f7db87d90>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bn_do.optimizer.lr = 0.001 # shift-M to merge in command mode\n",
    "model_bn_do.fit_generator(batches, epochs=12,\n",
    "                steps_per_epoch=steps_per_epoch,\n",
    "                validation_steps=validation_steps, \n",
    "                validation_data=test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENSEMBLE ACCROSS ALL THESE MODELS\n",
    "# TODO: MAKE 6 MODELS LIKE THIS and average them\n",
    "def fit_model():\n",
    "    model_bn_do = get_model_bn_do()\n",
    "    model_bn_do.fit_generator(batches, epochs=8,\n",
    "                steps_per_epoch=steps_per_epoch,\n",
    "                validation_steps=validation_steps, \n",
    "                validation_data=test_batches)\n",
    "    \n",
    "    model_bn_do.optimizer.lr = 0.1 \n",
    "    model_bn_do.fit_generator(batches, epochs=4,\n",
    "                steps_per_epoch=steps_per_epoch,\n",
    "                validation_steps=validation_steps, \n",
    "                validation_data=test_batches)\n",
    "    \n",
    "    model_bn_do.optimizer.lr = 0.01 \n",
    "    model_bn_do.fit_generator(batches, epochs=8,\n",
    "                steps_per_epoch=steps_per_epoch,\n",
    "                validation_steps=validation_steps, \n",
    "                validation_data=test_batches)\n",
    "    \n",
    "    model_bn_do.optimizer.lr = 0.001 \n",
    "    model_bn_do.fit_generator(batches, epochs=8,\n",
    "                steps_per_epoch=steps_per_epoch,\n",
    "                validation_steps=validation_steps, \n",
    "                validation_data=test_batches)\n",
    "    return model_bn_do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nguyentu/anaconda3/envs/py27_tf_cv/lib/python2.7/site-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
      "  \n",
      "/home/nguyentu/anaconda3/envs/py27_tf_cv/lib/python2.7/site-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
      "  \n",
      "/home/nguyentu/anaconda3/envs/py27_tf_cv/lib/python2.7/site-packages/ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/nguyentu/anaconda3/envs/py27_tf_cv/lib/python2.7/site-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "  del sys.path[0]\n",
      "/home/nguyentu/anaconda3/envs/py27_tf_cv/lib/python2.7/site-packages/keras/layers/core.py:630: UserWarning: `output_shape` argument not specified for layer lambda_8 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 1, 28, 28)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.4026 - acc: 0.8799 - val_loss: 7.0570 - val_acc: 0.1246\n",
      "Epoch 2/8\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.1552 - acc: 0.9532 - val_loss: 0.6693 - val_acc: 0.7895\n",
      "Epoch 3/8\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.1198 - acc: 0.9640 - val_loss: 0.0700 - val_acc: 0.9805\n",
      "Epoch 4/8\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.1145 - acc: 0.9666 - val_loss: 0.0591 - val_acc: 0.9852\n",
      "Epoch 5/8\n",
      "235/235 [==============================] - 5s 23ms/step - loss: 0.0952 - acc: 0.9719 - val_loss: 0.0682 - val_acc: 0.9773\n",
      "Epoch 6/8\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0842 - acc: 0.9741 - val_loss: 0.0629 - val_acc: 0.9793\n",
      "Epoch 7/8\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0847 - acc: 0.9738 - val_loss: 0.0344 - val_acc: 0.9883\n",
      "Epoch 8/8\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0816 - acc: 0.9748 - val_loss: 0.0519 - val_acc: 0.9816\n",
      "Epoch 1/4\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0741 - acc: 0.9757 - val_loss: 0.0384 - val_acc: 0.9891\n",
      "Epoch 2/4\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.0682 - acc: 0.9791 - val_loss: 0.0486 - val_acc: 0.9848\n",
      "Epoch 3/4\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.0665 - acc: 0.9793 - val_loss: 0.0641 - val_acc: 0.9801\n",
      "Epoch 4/4\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0671 - acc: 0.9787 - val_loss: 0.0537 - val_acc: 0.9812\n",
      "Epoch 1/8\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0588 - acc: 0.9814 - val_loss: 0.0583 - val_acc: 0.9789\n",
      "Epoch 2/8\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.0641 - acc: 0.9807 - val_loss: 0.0462 - val_acc: 0.9855\n",
      "Epoch 3/8\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.0582 - acc: 0.9822 - val_loss: 0.0420 - val_acc: 0.9867\n",
      "Epoch 4/8\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0642 - acc: 0.9805 - val_loss: 0.0503 - val_acc: 0.9824\n",
      "Epoch 5/8\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.0537 - acc: 0.9830 - val_loss: 0.0284 - val_acc: 0.9895\n",
      "Epoch 6/8\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.0520 - acc: 0.9837 - val_loss: 0.0473 - val_acc: 0.9859\n",
      "Epoch 7/8\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.0631 - acc: 0.9814 - val_loss: 0.0414 - val_acc: 0.9871\n",
      "Epoch 8/8\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0548 - acc: 0.9830 - val_loss: 0.0280 - val_acc: 0.9914\n",
      "Epoch 1/8\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0492 - acc: 0.9842 - val_loss: 0.0348 - val_acc: 0.9863\n",
      "Epoch 2/8\n",
      "235/235 [==============================] - 5s 23ms/step - loss: 0.0474 - acc: 0.9853 - val_loss: 0.0414 - val_acc: 0.9859\n",
      "Epoch 3/8\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.0496 - acc: 0.9845 - val_loss: 0.0422 - val_acc: 0.9863\n",
      "Epoch 4/8\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0540 - acc: 0.9832 - val_loss: 0.0417 - val_acc: 0.9871\n",
      "Epoch 5/8\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.0493 - acc: 0.9847 - val_loss: 0.0338 - val_acc: 0.9871\n",
      "Epoch 6/8\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0497 - acc: 0.9846 - val_loss: 0.0345 - val_acc: 0.9902\n",
      "Epoch 7/8\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.0430 - acc: 0.9874 - val_loss: 0.0284 - val_acc: 0.9918\n",
      "Epoch 8/8\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0504 - acc: 0.9851 - val_loss: 0.0337 - val_acc: 0.9902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nguyentu/anaconda3/envs/py27_tf_cv/lib/python2.7/site-packages/keras/layers/core.py:630: UserWarning: `output_shape` argument not specified for layer lambda_9 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 1, 28, 28)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.4016 - acc: 0.8803 - val_loss: 7.8458 - val_acc: 0.1223\n",
      "Epoch 2/8\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.1648 - acc: 0.9490 - val_loss: 0.3942 - val_acc: 0.8840\n",
      "Epoch 3/8\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.1255 - acc: 0.9616 - val_loss: 0.0975 - val_acc: 0.9676\n",
      "Epoch 4/8\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.1056 - acc: 0.9661 - val_loss: 0.0566 - val_acc: 0.9816\n",
      "Epoch 5/8\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0966 - acc: 0.9712 - val_loss: 0.0584 - val_acc: 0.9812\n",
      "Epoch 6/8\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.0867 - acc: 0.9739 - val_loss: 0.0729 - val_acc: 0.9766\n",
      "Epoch 7/8\n",
      "235/235 [==============================] - 5s 23ms/step - loss: 0.0737 - acc: 0.9769 - val_loss: 0.0512 - val_acc: 0.9816\n",
      "Epoch 8/8\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0740 - acc: 0.9785 - val_loss: 0.0472 - val_acc: 0.9844\n",
      "Epoch 1/4\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0683 - acc: 0.9793 - val_loss: 0.0620 - val_acc: 0.9805\n",
      "Epoch 2/4\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.0691 - acc: 0.9781 - val_loss: 0.0521 - val_acc: 0.9848\n",
      "Epoch 3/4\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.0679 - acc: 0.9791 - val_loss: 0.0547 - val_acc: 0.9840\n",
      "Epoch 4/4\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0598 - acc: 0.9805 - val_loss: 0.0414 - val_acc: 0.9887\n",
      "Epoch 1/8\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0688 - acc: 0.9790 - val_loss: 0.0426 - val_acc: 0.9836\n",
      "Epoch 2/8\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.0607 - acc: 0.9806 - val_loss: 0.0474 - val_acc: 0.9844\n",
      "Epoch 3/8\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.0568 - acc: 0.9834 - val_loss: 0.0569 - val_acc: 0.9824\n",
      "Epoch 4/8\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0543 - acc: 0.9834 - val_loss: 0.0327 - val_acc: 0.9902\n",
      "Epoch 5/8\n",
      "235/235 [==============================] - 5s 23ms/step - loss: 0.0564 - acc: 0.9829 - val_loss: 0.0371 - val_acc: 0.9883\n",
      "Epoch 6/8\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.0591 - acc: 0.9828 - val_loss: 0.0479 - val_acc: 0.9855\n",
      "Epoch 7/8\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.0527 - acc: 0.9834 - val_loss: 0.0405 - val_acc: 0.9883\n",
      "Epoch 8/8\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0547 - acc: 0.9829 - val_loss: 0.0326 - val_acc: 0.9910\n",
      "Epoch 1/8\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0423 - acc: 0.9869 - val_loss: 0.0409 - val_acc: 0.9883\n",
      "Epoch 2/8\n",
      "235/235 [==============================] - 5s 23ms/step - loss: 0.0505 - acc: 0.9844 - val_loss: 0.0398 - val_acc: 0.9840\n",
      "Epoch 3/8\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.0564 - acc: 0.9830 - val_loss: 0.0310 - val_acc: 0.9906\n",
      "Epoch 4/8\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0547 - acc: 0.9836 - val_loss: 0.0484 - val_acc: 0.9867\n",
      "Epoch 5/8\n",
      "235/235 [==============================] - 5s 23ms/step - loss: 0.0515 - acc: 0.9850 - val_loss: 0.0480 - val_acc: 0.9863\n",
      "Epoch 6/8\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.0456 - acc: 0.9860 - val_loss: 0.0345 - val_acc: 0.9887\n",
      "Epoch 7/8\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.0542 - acc: 0.9840 - val_loss: 0.0308 - val_acc: 0.9898\n",
      "Epoch 8/8\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0427 - acc: 0.9867 - val_loss: 0.0309 - val_acc: 0.9895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nguyentu/anaconda3/envs/py27_tf_cv/lib/python2.7/site-packages/keras/layers/core.py:630: UserWarning: `output_shape` argument not specified for layer lambda_10 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 1, 28, 28)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.4165 - acc: 0.8767 - val_loss: 6.4598 - val_acc: 0.1273\n",
      "Epoch 2/8\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.1735 - acc: 0.9501 - val_loss: 0.2286 - val_acc: 0.9277\n",
      "Epoch 3/8\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.1223 - acc: 0.9623 - val_loss: 0.1383 - val_acc: 0.9590\n",
      "Epoch 4/8\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.1184 - acc: 0.9661 - val_loss: 0.0657 - val_acc: 0.9797\n",
      "Epoch 5/8\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.0930 - acc: 0.9713 - val_loss: 0.0491 - val_acc: 0.9859\n",
      "Epoch 6/8\n",
      "235/235 [==============================] - 5s 23ms/step - loss: 0.0956 - acc: 0.9717 - val_loss: 0.0487 - val_acc: 0.9844\n",
      "Epoch 7/8\n",
      "235/235 [==============================] - 5s 23ms/step - loss: 0.0761 - acc: 0.9763 - val_loss: 0.0616 - val_acc: 0.9809\n",
      "Epoch 8/8\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0782 - acc: 0.9760 - val_loss: 0.0526 - val_acc: 0.9844\n",
      "Epoch 1/4\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0685 - acc: 0.9781 - val_loss: 0.0537 - val_acc: 0.9816\n",
      "Epoch 2/4\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.0680 - acc: 0.9770 - val_loss: 0.0584 - val_acc: 0.9797\n",
      "Epoch 3/4\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.0677 - acc: 0.9793 - val_loss: 0.0476 - val_acc: 0.9852\n",
      "Epoch 4/4\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0687 - acc: 0.9794 - val_loss: 0.0463 - val_acc: 0.9836\n",
      "Epoch 1/8\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0584 - acc: 0.9820 - val_loss: 0.0370 - val_acc: 0.9895\n",
      "Epoch 2/8\n",
      "235/235 [==============================] - 5s 23ms/step - loss: 0.0554 - acc: 0.9827 - val_loss: 0.0309 - val_acc: 0.9906\n",
      "Epoch 3/8\n",
      "235/235 [==============================] - 5s 23ms/step - loss: 0.0622 - acc: 0.9807 - val_loss: 0.0368 - val_acc: 0.9879\n",
      "Epoch 4/8\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0600 - acc: 0.9809 - val_loss: 0.0474 - val_acc: 0.9852\n",
      "Epoch 5/8\n",
      "235/235 [==============================] - 5s 23ms/step - loss: 0.0583 - acc: 0.9819 - val_loss: 0.0510 - val_acc: 0.9820\n",
      "Epoch 6/8\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0605 - acc: 0.9810 - val_loss: 0.0374 - val_acc: 0.9875\n",
      "Epoch 7/8\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0497 - acc: 0.9848 - val_loss: 0.0399 - val_acc: 0.9863\n",
      "Epoch 8/8\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0526 - acc: 0.9833 - val_loss: 0.0318 - val_acc: 0.9871\n",
      "Epoch 1/8\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0515 - acc: 0.9826 - val_loss: 0.0403 - val_acc: 0.9887\n",
      "Epoch 2/8\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.0500 - acc: 0.9830 - val_loss: 0.0355 - val_acc: 0.9910\n",
      "Epoch 3/8\n",
      "235/235 [==============================] - 5s 23ms/step - loss: 0.0545 - acc: 0.9834 - val_loss: 0.0394 - val_acc: 0.9887\n",
      "Epoch 4/8\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0469 - acc: 0.9866 - val_loss: 0.0287 - val_acc: 0.9922\n",
      "Epoch 5/8\n",
      "235/235 [==============================] - 5s 23ms/step - loss: 0.0481 - acc: 0.9854 - val_loss: 0.0414 - val_acc: 0.9852\n",
      "Epoch 6/8\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.0491 - acc: 0.9850 - val_loss: 0.0355 - val_acc: 0.9887\n",
      "Epoch 7/8\n",
      "235/235 [==============================] - 5s 23ms/step - loss: 0.0415 - acc: 0.9869 - val_loss: 0.0392 - val_acc: 0.9863\n",
      "Epoch 8/8\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0484 - acc: 0.9860 - val_loss: 0.0345 - val_acc: 0.9902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nguyentu/anaconda3/envs/py27_tf_cv/lib/python2.7/site-packages/keras/layers/core.py:630: UserWarning: `output_shape` argument not specified for layer lambda_11 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 1, 28, 28)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.4191 - acc: 0.8768 - val_loss: 8.2472 - val_acc: 0.1223\n",
      "Epoch 2/8\n",
      "235/235 [==============================] - 5s 23ms/step - loss: 0.1573 - acc: 0.9507 - val_loss: 0.2563 - val_acc: 0.9191\n",
      "Epoch 3/8\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.1167 - acc: 0.9644 - val_loss: 0.0792 - val_acc: 0.9754\n",
      "Epoch 4/8\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.1060 - acc: 0.9688 - val_loss: 0.0643 - val_acc: 0.9797\n",
      "Epoch 5/8\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.0818 - acc: 0.9751 - val_loss: 0.0500 - val_acc: 0.9836\n",
      "Epoch 6/8\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.0808 - acc: 0.9742 - val_loss: 0.0548 - val_acc: 0.9809\n",
      "Epoch 7/8\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0778 - acc: 0.9764 - val_loss: 0.0389 - val_acc: 0.9883\n",
      "Epoch 8/8\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0804 - acc: 0.9763 - val_loss: 0.0426 - val_acc: 0.9855\n",
      "Epoch 1/4\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0708 - acc: 0.9773 - val_loss: 0.0528 - val_acc: 0.9840\n",
      "Epoch 2/4\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.0636 - acc: 0.9809 - val_loss: 0.0529 - val_acc: 0.9832\n",
      "Epoch 3/4\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.0634 - acc: 0.9802 - val_loss: 0.0425 - val_acc: 0.9879\n",
      "Epoch 4/4\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0634 - acc: 0.9816 - val_loss: 0.0475 - val_acc: 0.9840\n",
      "Epoch 1/8\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0559 - acc: 0.9826 - val_loss: 0.0377 - val_acc: 0.9887\n",
      "Epoch 2/8\n",
      "235/235 [==============================] - 5s 23ms/step - loss: 0.0597 - acc: 0.9804 - val_loss: 0.0433 - val_acc: 0.9863\n",
      "Epoch 3/8\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.0615 - acc: 0.9803 - val_loss: 0.0443 - val_acc: 0.9867\n",
      "Epoch 4/8\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0594 - acc: 0.9822 - val_loss: 0.0369 - val_acc: 0.9891\n",
      "Epoch 5/8\n",
      "235/235 [==============================] - 5s 23ms/step - loss: 0.0514 - acc: 0.9836 - val_loss: 0.0351 - val_acc: 0.9887\n",
      "Epoch 6/8\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.0493 - acc: 0.9849 - val_loss: 0.0499 - val_acc: 0.9859\n",
      "Epoch 7/8\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.0602 - acc: 0.9826 - val_loss: 0.0348 - val_acc: 0.9883\n",
      "Epoch 8/8\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0548 - acc: 0.9828 - val_loss: 0.0306 - val_acc: 0.9902\n",
      "Epoch 1/8\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0523 - acc: 0.9838 - val_loss: 0.0400 - val_acc: 0.9891\n",
      "Epoch 2/8\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.0482 - acc: 0.9851 - val_loss: 0.0418 - val_acc: 0.9875\n",
      "Epoch 3/8\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.0528 - acc: 0.9836 - val_loss: 0.0352 - val_acc: 0.9859\n",
      "Epoch 4/8\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0481 - acc: 0.9854 - val_loss: 0.0476 - val_acc: 0.9867\n",
      "Epoch 5/8\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.0501 - acc: 0.9854 - val_loss: 0.0298 - val_acc: 0.9910\n",
      "Epoch 6/8\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.0477 - acc: 0.9856 - val_loss: 0.0390 - val_acc: 0.9887\n",
      "Epoch 7/8\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0419 - acc: 0.9879 - val_loss: 0.0385 - val_acc: 0.9875\n",
      "Epoch 8/8\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0538 - acc: 0.9834 - val_loss: 0.0384 - val_acc: 0.9895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nguyentu/anaconda3/envs/py27_tf_cv/lib/python2.7/site-packages/keras/layers/core.py:630: UserWarning: `output_shape` argument not specified for layer lambda_12 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 1, 28, 28)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.4188 - acc: 0.8760 - val_loss: 8.3897 - val_acc: 0.1223\n",
      "Epoch 2/8\n",
      "235/235 [==============================] - 5s 23ms/step - loss: 0.1586 - acc: 0.9516 - val_loss: 0.2203 - val_acc: 0.9359\n",
      "Epoch 3/8\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.1222 - acc: 0.9622 - val_loss: 0.0891 - val_acc: 0.9676\n",
      "Epoch 4/8\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.1041 - acc: 0.9696 - val_loss: 0.0674 - val_acc: 0.9781\n",
      "Epoch 5/8\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.0860 - acc: 0.9740 - val_loss: 0.0629 - val_acc: 0.9805\n",
      "Epoch 6/8\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.0869 - acc: 0.9737 - val_loss: 0.0606 - val_acc: 0.9773\n",
      "Epoch 7/8\n",
      "235/235 [==============================] - 5s 23ms/step - loss: 0.0745 - acc: 0.9777 - val_loss: 0.0532 - val_acc: 0.9816\n",
      "Epoch 8/8\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0748 - acc: 0.9769 - val_loss: 0.0447 - val_acc: 0.9871\n",
      "Epoch 1/4\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0684 - acc: 0.9791 - val_loss: 0.0465 - val_acc: 0.9883\n",
      "Epoch 2/4\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.0749 - acc: 0.9775 - val_loss: 0.0560 - val_acc: 0.9832\n",
      "Epoch 3/4\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0616 - acc: 0.9805 - val_loss: 0.0423 - val_acc: 0.9887\n",
      "Epoch 4/4\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0629 - acc: 0.9814 - val_loss: 0.0385 - val_acc: 0.9871\n",
      "Epoch 1/8\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.0549 - acc: 0.9826 - val_loss: 0.0352 - val_acc: 0.9895\n",
      "Epoch 2/8\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.0541 - acc: 0.9828 - val_loss: 0.0441 - val_acc: 0.9863\n",
      "Epoch 3/8\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0635 - acc: 0.9809 - val_loss: 0.0393 - val_acc: 0.9879\n",
      "Epoch 4/8\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0640 - acc: 0.9807 - val_loss: 0.0297 - val_acc: 0.9914\n",
      "Epoch 5/8\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.0576 - acc: 0.9818 - val_loss: 0.0496 - val_acc: 0.9844\n",
      "Epoch 6/8\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0565 - acc: 0.9825 - val_loss: 0.0329 - val_acc: 0.9883\n",
      "Epoch 7/8\n",
      "235/235 [==============================] - 5s 23ms/step - loss: 0.0585 - acc: 0.9820 - val_loss: 0.0457 - val_acc: 0.9863\n",
      "Epoch 8/8\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0545 - acc: 0.9843 - val_loss: 0.0295 - val_acc: 0.9910\n",
      "Epoch 1/8\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0511 - acc: 0.9840 - val_loss: 0.0442 - val_acc: 0.9863\n",
      "Epoch 2/8\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.0557 - acc: 0.9827 - val_loss: 0.0378 - val_acc: 0.9879\n",
      "Epoch 3/8\n",
      "235/235 [==============================] - 5s 23ms/step - loss: 0.0500 - acc: 0.9844 - val_loss: 0.0383 - val_acc: 0.9895\n",
      "Epoch 4/8\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0516 - acc: 0.9842 - val_loss: 0.0297 - val_acc: 0.9910\n",
      "Epoch 5/8\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.0451 - acc: 0.9858 - val_loss: 0.0324 - val_acc: 0.9863\n",
      "Epoch 6/8\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.0467 - acc: 0.9854 - val_loss: 0.0363 - val_acc: 0.9887\n",
      "Epoch 7/8\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0456 - acc: 0.9858 - val_loss: 0.0369 - val_acc: 0.9898\n",
      "Epoch 8/8\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0486 - acc: 0.9850 - val_loss: 0.0411 - val_acc: 0.9867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nguyentu/anaconda3/envs/py27_tf_cv/lib/python2.7/site-packages/keras/layers/core.py:630: UserWarning: `output_shape` argument not specified for layer lambda_13 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 1, 28, 28)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.4120 - acc: 0.8769 - val_loss: 6.9922 - val_acc: 0.1230\n",
      "Epoch 2/8\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.1531 - acc: 0.9549 - val_loss: 0.1930 - val_acc: 0.9352\n",
      "Epoch 3/8\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.1228 - acc: 0.9646 - val_loss: 0.0909 - val_acc: 0.9715\n",
      "Epoch 4/8\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0973 - acc: 0.9701 - val_loss: 0.0674 - val_acc: 0.9773\n",
      "Epoch 5/8\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.0885 - acc: 0.9727 - val_loss: 0.0547 - val_acc: 0.9840\n",
      "Epoch 6/8\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.0796 - acc: 0.9759 - val_loss: 0.0422 - val_acc: 0.9848\n",
      "Epoch 7/8\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.0884 - acc: 0.9743 - val_loss: 0.0520 - val_acc: 0.9855\n",
      "Epoch 8/8\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0759 - acc: 0.9773 - val_loss: 0.0427 - val_acc: 0.9852\n",
      "Epoch 1/4\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0676 - acc: 0.9798 - val_loss: 0.0549 - val_acc: 0.9797\n",
      "Epoch 2/4\n",
      "235/235 [==============================] - 5s 23ms/step - loss: 0.0645 - acc: 0.9795 - val_loss: 0.0607 - val_acc: 0.9789\n",
      "Epoch 3/4\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.0704 - acc: 0.9791 - val_loss: 0.0428 - val_acc: 0.9867\n",
      "Epoch 4/4\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0615 - acc: 0.9822 - val_loss: 0.0396 - val_acc: 0.9879\n",
      "Epoch 1/8\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0646 - acc: 0.9797 - val_loss: 0.0417 - val_acc: 0.9883\n",
      "Epoch 2/8\n",
      "235/235 [==============================] - 5s 23ms/step - loss: 0.0562 - acc: 0.9836 - val_loss: 0.0436 - val_acc: 0.9859\n",
      "Epoch 3/8\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.0574 - acc: 0.9818 - val_loss: 0.0383 - val_acc: 0.9883\n",
      "Epoch 4/8\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0629 - acc: 0.9825 - val_loss: 0.0367 - val_acc: 0.9895\n",
      "Epoch 5/8\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0513 - acc: 0.9838 - val_loss: 0.0384 - val_acc: 0.9879\n",
      "Epoch 6/8\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0562 - acc: 0.9824 - val_loss: 0.0412 - val_acc: 0.9855\n",
      "Epoch 7/8\n",
      "235/235 [==============================] - 5s 23ms/step - loss: 0.0543 - acc: 0.9824 - val_loss: 0.0367 - val_acc: 0.9879\n",
      "Epoch 8/8\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0532 - acc: 0.9831 - val_loss: 0.0415 - val_acc: 0.9898\n",
      "Epoch 1/8\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0499 - acc: 0.9854 - val_loss: 0.0379 - val_acc: 0.9871\n",
      "Epoch 2/8\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.0460 - acc: 0.9858 - val_loss: 0.0353 - val_acc: 0.9883\n",
      "Epoch 3/8\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.0522 - acc: 0.9848 - val_loss: 0.0291 - val_acc: 0.9898\n",
      "Epoch 4/8\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0501 - acc: 0.9844 - val_loss: 0.0308 - val_acc: 0.9891\n",
      "Epoch 5/8\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.0454 - acc: 0.9860 - val_loss: 0.0401 - val_acc: 0.9883\n",
      "Epoch 6/8\n",
      "235/235 [==============================] - 5s 23ms/step - loss: 0.0538 - acc: 0.9824 - val_loss: 0.0403 - val_acc: 0.9871\n",
      "Epoch 7/8\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.0464 - acc: 0.9849 - val_loss: 0.0347 - val_acc: 0.9887\n",
      "Epoch 8/8\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0492 - acc: 0.9845 - val_loss: 0.0378 - val_acc: 0.9887\n"
     ]
    }
   ],
   "source": [
    "models = [fit_model() for i in range(6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME_DIR = os.getenv('HOME')\n",
    "path = HOME_DIR + '/data/mnist/'\n",
    "model_path = path + 'models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, m in enumerate(models):\n",
    "    m.save_weights(model_path+'cnn-mnist-'+str(i)+'.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 37us/step\n",
      "10000/10000 [==============================] - 0s 36us/step\n",
      "10000/10000 [==============================] - 0s 36us/step\n",
      "10000/10000 [==============================] - 0s 36us/step\n",
      "10000/10000 [==============================] - 0s 36us/step\n",
      "10000/10000 [==============================] - 0s 36us/step\n"
     ]
    }
   ],
   "source": [
    "evals = np.array([m.evaluate(X_test, y_test, batch_size=256) for m in models])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0193, 0.9937])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evals.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = np.stack([m.predict(X_test, batch_size=256) for m in models])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 10000, 10)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 10), (10000, 10))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_preds = all_preds.mean(axis=0).astype(np.float64)\n",
    "avg_preds.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras metric function takes (y_true, y_pred)\n",
    "# it returns array of size [n_samples] with interger values in [0, 1]\n",
    "# need to do eval() and mean() to get the accuracy over the whole set\n",
    "ensemble_acc = keras.metrics.categorical_accuracy(\n",
    "    y_test, avg_preds).eval().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "() (10000, 10) (10000, 10)\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.] [4.7674e-07 4.2028e-07 1.1153e-07 2.0570e-07 4.2358e-08 9.1133e-09 3.0495e-10 9.9999e-01 1.4833e-09\n",
      " 5.5657e-06]\n",
      "float64 float64\n",
      "0.9963\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(ensemble_acc.shape, avg_preds.shape, y_test.shape)\n",
    "print(y_test[0,:], avg_preds[0,:])\n",
    "print(y_test.dtype, avg_preds.dtype)\n",
    "print(ensemble_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# deeper look into the categorical_accuracy function in keras\n",
    "from keras.metrics import *\n",
    "res = categorical_accuracy(\n",
    "    np.array([[0, 1.0, 0], [1.0, 0.0, 0]], dtype=float), \n",
    "    np.array([[0, 1.0, 0], [0.0, 1.0, 0]], dtype=float)).eval()\n",
    "res.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: TRAIN FOR LONGER TIME AND PARAM SEARCH FOR THE DATA\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
